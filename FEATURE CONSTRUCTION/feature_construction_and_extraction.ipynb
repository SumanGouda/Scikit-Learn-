{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7496edbc",
   "metadata": {},
   "source": [
    "## Feature Construction\n",
    "\n",
    "**This is total based on your experience, no mathematics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5269ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea434e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/100-days-of-machine-learning/refs/heads/main/day45-feature-construction-and-feature-splitting/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a43ea8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pclass",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SibSp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Parch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Survived",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "78373d6f-2841-4990-8ca5-c1a5145d1c85",
       "rows": [
        [
         "0",
         "22.0",
         "3",
         "1",
         "0",
         "0"
        ],
        [
         "1",
         "38.0",
         "1",
         "1",
         "0",
         "1"
        ],
        [
         "2",
         "26.0",
         "3",
         "0",
         "0",
         "1"
        ],
        [
         "3",
         "35.0",
         "1",
         "1",
         "0",
         "1"
        ],
        [
         "4",
         "35.0",
         "3",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Pclass  SibSp  Parch  Survived\n",
       "0  22.0       3      1      0         0\n",
       "1  38.0       1      1      0         1\n",
       "2  26.0       3      0      0         1\n",
       "3  35.0       1      1      0         1\n",
       "4  35.0       3      0      0         0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Age', 'Pclass', 'SibSp', 'Parch', 'Survived']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c3447d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6933333333333332)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "X  =df.drop(columns=['Survived'])\n",
    "y = df['Survived']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "np.mean(cross_val_score(LogisticRegression(), X, y, cv=20, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cee404",
   "metadata": {},
   "source": [
    "### Applying Feature Construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e5fe2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7326\n",
      "Standard Deviation: 0.0863\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create family_members column\n",
    "df['family_members'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "# Handle potential null values (fill with 1 assuming person is alone if data missing)\n",
    "df['family_members'] = df['family_members'].fillna(1).astype(int)  # Convert to int after fill\n",
    "\n",
    "def family_size_count(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "        if x == 1:\n",
    "            return 'Alone'\n",
    "        elif 2 <= x <= 4:\n",
    "            return 'Small'\n",
    "        else:\n",
    "            return 'Large'\n",
    "    except (ValueError, TypeError):\n",
    "        return 'Alone'\n",
    "\n",
    "# Apply the function\n",
    "df['family_size'] = df['family_members'].apply(family_size_count)\n",
    "\n",
    "# Convert categorical variables to dummy/indicator variables\n",
    "X_new = pd.get_dummies(df.drop(columns=['Survived']), drop_first=True)\n",
    "y_new = df['Survived']\n",
    "\n",
    "# Calculate cross-validation score\n",
    "logreg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "cv_scores = cross_val_score(logreg, X_new, y_new, cv=20, scoring='accuracy')\n",
    "print(f\"Mean Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0571177d",
   "metadata": {},
   "source": [
    "## Curse of Dimensionality in Machine Learning\n",
    "\n",
    "### Definition\n",
    "The \"curse of dimensionality\" refers to various challenges that arise when working with high-dimensional data (many features/variables), where the performance of machine learning algorithms often degrades as the number of dimensions increases.\n",
    "\n",
    "### Key Problems\n",
    "\n",
    "#### 1. Data Sparsity\n",
    "- In high dimensions, data points become increasingly isolated\n",
    "- Volume of space grows exponentially with dimensions, making data sparse\n",
    "- Requires exponentially more data to maintain density\n",
    "\n",
    "#### 2. Distance Measures Become Meaningless\n",
    "- All pairwise distances converge to the same value\n",
    "- Distinction between \"near\" and \"far\" points diminishes\n",
    "- Affects distance-based algorithms (k-NN, clustering)\n",
    "\n",
    "#### 3. Overfitting Risk Increases\n",
    "- Model complexity grows with dimensionality\n",
    "- More parameters needed â†’ higher risk of overfitting\n",
    "- Need for more training data grows exponentially\n",
    "\n",
    "#### 4. Computational Challenges\n",
    "- Higher memory and processing requirements\n",
    "- Algorithms become slower (often non-linearly)\n",
    "\n",
    "### Common Solutions\n",
    "\n",
    "#### Dimensionality Reduction\n",
    "- **Feature Selection**: Choose most relevant features\n",
    "- **Feature Extraction**: PCA, t-SNE, UMAP, autoencoders\n",
    "\n",
    "#### Regularization\n",
    "- L1/L2 regularization to prevent overfitting\n",
    "- Dropout in neural networks\n",
    "\n",
    "#### Alternative Algorithms\n",
    "- Tree-based methods often handle high dimensions better\n",
    "- Use of manifolds or specialized high-dim algorithms\n",
    "\n",
    "### Visualization Challenge\n",
    "- Human intuition fails beyond 3D\n",
    "- Projection techniques needed to visualize high-D data\n",
    "\n",
    "### Notable Quotes\n",
    "> \"In high dimensions, all data is sparse.\" - Richard Bellman (coined the term)\n",
    "> \"The curse of dimensionality is the bane of machine learning.\" - Common saying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bda8c",
   "metadata": {},
   "source": [
    "## <span style=\"color: #00ddffff;\"><i>PCA</i></span>\n",
    "\n",
    "- Is a technique in which a higher dimensional data can be converted to a lower dimensional data while keeping the quality of the data unchanged>\n",
    "\n",
    "- Can convert a multidimensiional data into a 3D so that it can be visible \n",
    "\n",
    "**Cases where you had to pick <mark>one feature out of two</mark>**\n",
    "* There you can plot the graph between both the features and check whose spread is wider in it's axis and then keep that feature. \n",
    "\n",
    "**<i>For cases wehre both the features gets equal spread there we use the concept of <mark>feature extraction</mark></i>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5761e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
