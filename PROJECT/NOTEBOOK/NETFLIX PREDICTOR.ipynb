{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5302f00",
   "metadata": {},
   "source": [
    "# Netflix search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a9b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smarter Recommendations for 'Kota Factory':\n",
      "Little Things (Score: 10)\n",
      "Taj Mahal 1989 (Score: 10)\n",
      "Mismatched (Score: 10)\n",
      "Bhaag Beanie Bhaag (Score: 10)\n",
      "Yeh Meri Family (Score: 9)\n",
      "Rishta.com (Score: 9)\n",
      "Bh Se Bhade (Score: 9)\n",
      "Engineering Girls (Score: 9)\n",
      "College Romance (Score: 9)\n",
      "My Dear Warrior (Score: 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "netflix_data = pd.read_csv(r\"D:\\PYTON PROGRAMMING\\PYTHON FILES\\Scikit-Learn\\PROJECT\\DATA\\netflix_titles.csv\")\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# Convert 'type' column to numeric\n",
    "netflix_data['type_num'] = netflix_data['type'].map({'TV Show': 0, 'Movie': 1})\n",
    "\n",
    "# Scale 'release_year' and 'duration'\n",
    "scaler = MinMaxScaler()\n",
    "netflix_data['release_year_scaled'] = scaler.fit_transform(netflix_data[['release_year']])\n",
    "\n",
    "def extract_duration(val):\n",
    "    try:\n",
    "        return int(val.split(' ')[0])\n",
    "    except:\n",
    "        return None\n",
    "netflix_data['duration_num'] = netflix_data['duration'].apply(extract_duration)\n",
    "netflix_data['duration_num_scaled'] = scaler.fit_transform(netflix_data[['duration_num']])\n",
    "\n",
    "# Convert generes to binary\n",
    "netflix_data['genre_list'] = netflix_data['listed_in'].apply(lambda x: x.split(', '))\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_netflix_data = pd.DataFrame(mlb.fit_transform(netflix_data['genre_list']), columns=mlb.classes_, index=netflix_data.index) \n",
    "netflix_data = pd.concat([netflix_data, genre_netflix_data], axis=1) \n",
    "\n",
    "# Cast and Country\n",
    "netflix_data['cast'] = netflix_data['cast'].fillna('')\n",
    "netflix_data['country'] = netflix_data['country'].fillna('')        # Fill missing values\n",
    "\n",
    "# TF-IDF for cast\n",
    "cast_vectorizer = TfidfVectorizer(max_features=50)\n",
    "cast_matrix = cast_vectorizer.fit_transform(netflix_data['cast'])\n",
    "\n",
    "# TF-IDF for country\n",
    "country_vectorizer = TfidfVectorizer(max_features=20)  # can tweak max_features as needed\n",
    "country_matrix = country_vectorizer.fit_transform(netflix_data['country'])\n",
    "\n",
    "# Combine all features\n",
    "features = np.hstack([\n",
    "    netflix_data[['type_num', 'release_year_scaled', 'duration_num_scaled']].fillna(0).values,\n",
    "    genre_netflix_data.values,\n",
    "    cast_matrix.toarray(),\n",
    "    country_matrix.toarray()\n",
    "])\n",
    "\n",
    "# Model Training\n",
    "model_knn = NearestNeighbors(n_neighbors=6, metric='cosine')\n",
    "model_knn.fit(features)\n",
    "\n",
    "# Testing the model\n",
    "title = \"Kota Factory\"\n",
    "filtered_df = netflix_data[netflix_data['title'] == title]\n",
    "\n",
    "if not filtered_df.empty:\n",
    "    target_index = filtered_df.index[0]     # Returns the row number in the actual row number before filtering.\n",
    "    distances, indices = model_knn.kneighbors([features[target_index]], n_neighbors=30)\n",
    "\n",
    "    target_genres = set(netflix_data.loc[target_index, 'genre_list'])\n",
    "    target_year = netflix_data.loc[target_index, 'release_year']\n",
    "    target_type = netflix_data.loc[target_index, 'type']\n",
    "    target_country = netflix_data.loc[target_index, 'country']\n",
    "\n",
    "    scored_neighbors = []\n",
    "\n",
    "    for i in indices[0][1:]:  # Skip the first—it’s the query itself\n",
    "        row = netflix_data.loc[i]\n",
    "        score = 0\n",
    "\n",
    "        # Genre match\n",
    "        if target_genres.intersection(row['genre_list']):\n",
    "            score += 5\n",
    "        \n",
    "        # Type match\n",
    "        if row['type'] == target_type:\n",
    "            score += 3\n",
    "        \n",
    "        # Year proximity\n",
    "        if abs(row['release_year'] - target_year) <= 2:\n",
    "            score += 1\n",
    "\n",
    "        # Country match\n",
    "        if row['country'] == target_country:\n",
    "            score += 1\n",
    "        scored_neighbors.append((score, i))\n",
    "\n",
    "    # Sort and show top results\n",
    "    scored_neighbors.sort(reverse=True)\n",
    "    print(f\"Smarter Recommendations for '{title}':\")\n",
    "    for score, idx in scored_neighbors[:10]:\n",
    "        print(f\"{netflix_data.loc[idx, 'title']} (Score: {score})\")\n",
    "else:\n",
    "    print(f\"❌ Title '{title}' not found in the dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
